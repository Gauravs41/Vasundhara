{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vanilla GANs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gauravs41/Vasundhara/blob/master/Vanilla_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvZ1ONE1kENi",
        "colab_type": "text"
      },
      "source": [
        "# Generative Adversarial Networks with TensorFlow\n",
        "We will try to build a GAN that is able to generate Handwritten Digit with TensorFlow from Scratch.\n",
        "\n",
        "# Setup\n",
        "Used Libraries:\n",
        "*   matplotlib\n",
        "*   numpy\n",
        "*   tensorflow\n",
        "\n",
        "tensorflow.examples.tutorials.mnist will automatically download the MNIST dataset to get you up and running quickly. MNIST dataset set of hundreads of Handwritten digits images. Be sure to have matplotlib installed to actually see the images. The download is around 50MB large, so be sure to have enough disk space and a stable internet connection ready.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gt47SdpCowj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Importing libraries \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from   tensorflow.examples.tutorials.mnist import input_data\n",
        "from IPython.display import clear_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMJkNUFcCxP0",
        "colab_type": "code",
        "outputId": "66897d0a-2240-4e39-d29b-b9b44dc78234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "##Reading data \n",
        "df = input_data.read_data_sets(\"/tmp/data/\",one_hot=True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig0qvqByACW-",
        "colab_type": "text"
      },
      "source": [
        "![GANs Diagram](https://skymind.ai/images/wiki/GANs.png)\n",
        "Image has 28*28 Dimension so for flattern data has linear 784 dimension.\n",
        "Generator and discriminator hidden layer Dimension is 256 and Given Noise Dimension is 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Wjo2DgC05d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Neural Network Parameters\n",
        "### 28*28=784\n",
        "\n",
        "img_dim=784\n",
        "gen_dim=256\n",
        "disc_dim=256\n",
        "noise_dim=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWS3JJlTNOCA",
        "colab_type": "text"
      },
      "source": [
        "# Defining network input\n",
        "Before we can start defining our two networks, we are going to define our inputs. We are doing this to not clutter the training function any more than it already is. Here, we are simply defining TensorFlow Placeholders for our real and fake inputs and for the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN4bBZlGC6E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Tensorflow data inputs\n",
        "\n",
        "gen_inp=tf.placeholder(tf.float32,shape=[None,noise_dim])\n",
        "disc_inp=tf.placeholder(tf.float32,shape=[None,img_dim])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K3rDwReC8we",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Neural Network training parameters\n",
        "\n",
        "batch_size=128\n",
        "num_steps=80000\n",
        "learning_rate=2e-4\n",
        "display_step=20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OGS1aG7Nj94",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLwpcpNUDGY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Weights function\n",
        "\n",
        "def weight_init(shape):\n",
        "    return tf.random_normal(shape=shape,stddev=1. / tf.sqrt(shape[0] / 2.))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr2PpFDJDHq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Model Architechture Weights\n",
        "\n",
        "W={\"w1\":tf.Variable(weight_init([noise_dim,gen_dim])),\n",
        "   \"w2\": tf.Variable(weight_init([gen_dim,img_dim])),\n",
        "   \"w3\": tf.Variable(weight_init([img_dim,disc_dim])), \n",
        "   \"w4\": tf.Variable(weight_init([disc_dim,1]))} \n",
        "\n",
        "b={\"b1\":tf.Variable(tf.zeros([gen_dim])),\n",
        "   \"b2\":tf.Variable(tf.zeros([img_dim])),\n",
        "   \"b3\":tf.Variable(tf.zeros([disc_dim])),\n",
        "   \"b4\":tf.Variable(tf.zeros([1]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFoTCoP73T4w",
        "colab_type": "text"
      },
      "source": [
        "The discriminator is the “art critic”, who tries to distinguish between real and fake images. Simply said, this is a neural network for image classification. The discriminator network consists of two layers.\n",
        "\n",
        "The generator goes the other way: It is the artist who is trying to fool the discriminator. In here, we are doing the same as in the discriminator, just in the other direction.\n",
        "\n",
        "First, we take our input, called x, and feed it into our first layer. In first layer we performs a matrix multiplication and then performs batch normalization and a leaky ReLu as well. and in second layer we do sigmoid transition instead of ReLu.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gybcpKntI3Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Model Architechture \n",
        "\n",
        "##Generator \n",
        "\n",
        "def gen_fun(x):\n",
        "    h1=tf.matmul(x,W[\"w1\"])\n",
        "    h1=tf.add(h1,b[\"b1\"])\n",
        "    h1=tf.nn.relu(h1)\n",
        "    \n",
        "    h1=tf.matmul(h1,W[\"w2\"])\n",
        "    h1=tf.add(h1,b[\"b2\"])\n",
        "    h1=tf.nn.sigmoid(h1)\n",
        "    \n",
        "    return h1\n",
        "\n",
        "\n",
        "def disc_fun(x):\n",
        "    h2=tf.matmul(x,W[\"w3\"])\n",
        "    h2=tf.add(h2,b[\"b3\"])\n",
        "    h2=tf.nn.relu(h2)\n",
        "    \n",
        "    h2=tf.matmul(h2,W[\"w4\"])\n",
        "    h2=tf.add(h2,b[\"b4\"])\n",
        "    h2=tf.nn.sigmoid(h2)\n",
        "    \n",
        "    return h2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS3D5-xGxI3h",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Optimization\n",
        "Rather than just having a single loss function, we need to define three: The loss of the generator, the loss of the discriminator when using real images and the loss of the discriminator when using fake images. The sum of the fake image and real image loss is the overall discriminator loss.\n",
        "Here we using AdamOptimizer which is similar to Gradient descent. if disc_fake_out is 1 (means descriminator is fooled) then cost of generator will be reduce by less amount else if output is 0 then cost will be reduce by high amount. Same but in reverse optimzation is done for discriminator cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtC0pxvHsXW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Cost function Optimization & Model Evaluation\n",
        "\n",
        "gen_out=gen_fun(gen_inp)\n",
        "\n",
        "disc_real_out=disc_fun(disc_inp)\n",
        "disc_fake_out=disc_fun(gen_out)\n",
        "\n",
        "optim_gen=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "optim_disc=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "cost_gen=-tf.reduce_mean(tf.log(disc_fake_out))\n",
        "cost_disc=-tf.reduce_mean(tf.log(disc_real_out)+tf.log(1.-disc_fake_out))\n",
        "\n",
        "###Generator and Discriminator Variables\n",
        "vars_gen = [W['w1'], W['w2'],b['b1'], b['b2']]\n",
        "vars_disc = [W['w3'],W['w4'],b['b3'], b['b4']]\n",
        "\n",
        "\n",
        "training_gen=optim_gen.minimize(cost_gen,var_list=vars_gen)\n",
        "training_disc=optim_gen.minimize(cost_disc,var_list=vars_disc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3J2y6r0SUF_",
        "colab_type": "text"
      },
      "source": [
        "# Training and Visualization\n",
        "Now, we just get our inputs, losses and optimizers which we defined before, call a TensorFlow session and run it batch per batch. Every 2000 steps we are printing out the current progress by showing the generated image and loss. Now lean back and see the faces show up slowly but steady - and we mean slowly but steady! This progress can take up some minutes based on your setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwRnt5zE_aAH",
        "colab_type": "code",
        "outputId": "0d4d2385-c1a6-4a57-d73e-fc8b6848b665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "source": [
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "###Staring the Model training Session\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    for step in range(1, num_steps+1):\n",
        "        batch_x, _ = df.train.next_batch(batch_size)\n",
        "        \n",
        "        # Generate noise to feed to the generator\n",
        "        noise_temp = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
        "        \n",
        "        # Run optimization op (backprop)\n",
        "        feed_dict = {disc_inp: batch_x, gen_inp: noise_temp}\n",
        "        _, _, gl, dl = sess.run([training_gen, training_disc, cost_gen, cost_disc],\n",
        "                            feed_dict=feed_dict)\n",
        "        if step % 2000 == 0 or step == 1:\n",
        "            clear_output()\n",
        "            print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (step, gl, dl))\n",
        "             # Generating the  images using the generator network\n",
        "            n = 6\n",
        "            canvas = np.empty((28 * n, 28 * n))\n",
        "\n",
        "            for i in range(n):\n",
        "              # Noise input.\n",
        "              z = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
        "              # Generate image from noise.\n",
        "              g = sess.run(gen_out, feed_dict={gen_inp: z})\n",
        "              # Reverse colours for better display\n",
        "              g = -1 * (g - 1)\n",
        "              for j in range(n):\n",
        "                # Draw the generated digits\n",
        "                canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
        "\n",
        "            plt.figure(figsize=(n, n))\n",
        "            plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
        "            plt.show()\n",
        "    print(\"Finished!\")\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 98000: Generator Loss: nan, Discriminator Loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAFoCAYAAAB3+xGSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-a33cdf2e0314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdisc_inp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_inp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnoise_temp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         _, _, gl, dl = sess.run([training_gen, training_disc, cost_gen, cost_disc],\n\u001b[0;32m---> 18\u001b[0;31m                             feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}